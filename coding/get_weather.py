#!/usr/bin/env python# -*- coding: utf-8 -*-# @Time    : 2018/6/6 上午8:30# @Author  : ziyi# @File    : get_weather.py# @Software: PyCharmfrom selenium import webdriverfrom bs4 import BeautifulSoupimport reimport randomimport  requestsfrom requests import RequestExceptionimport timedef get_header():    user_agent_list = [        "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/22.0.1207.1 Safari/537.1", \        "Mozilla/5.0 (X11; CrOS i686 2268.111.0) AppleWebKit/536.11 (KHTML, like Gecko) Chrome/20.0.1132.57 Safari/536.11", \        "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.6 (KHTML, like Gecko) Chrome/20.0.1092.0 Safari/536.6", \        "Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.6 (KHTML, like Gecko) Chrome/20.0.1090.0 Safari/536.6", \        "Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/19.77.34.5 Safari/537.1", \        "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/536.5 (KHTML, like Gecko) Chrome/19.0.1084.9 Safari/536.5", \        "Mozilla/5.0 (Windows NT 6.0) AppleWebKit/536.5 (KHTML, like Gecko) Chrome/19.0.1084.36 Safari/536.5", \        "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3", \        "Mozilla/5.0 (Windows NT 5.1) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3", \        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_0) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3", \        "Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1062.0 Safari/536.3", \        "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1062.0 Safari/536.3", \        "Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3"    ]    headers = {'User-Agent': random.choice(user_agent_list)}    return headersdef get_html():    headers = get_header()    soup = None    url = "http://www.weather.com.cn/weather/101190101.shtml"    try:        response = requests.get(url, timeout=30, headers=headers)        if response.status_code == 200:            # 解析乱码的解决情况            response.encoding = response.apparent_encoding            html = response.text            soup = BeautifulSoup(html, 'html.parser')  # 设置解析器为“html”            # print(soup)        else:            print('获取不到', url, response.status_code)    except RequestException as e:        print('获取不到', url, e)    time.sleep(3)    return soupdef get_weather():    # 获取第二天的天气的情况    soup = get_html()    # 根据属性模糊匹配内容    tomorrow = soup.findAll(name="li", attrs={"class": re.compile(r"sky skyid(\s\w+)?")})[1]    # print(tomorrow)    # tomorrow = soup.find('li',  class_="sky skyid lv3") #第一个包含class="sky skyid lv3"的li标签即为明天的天气的情况    weather = tomorrow.find('p', class_='wea').string    high = tomorrow.find('p', class_='tem').span.string    low = tomorrow.find('p', class_='tem').i.string    # print('最低温度:' + temperatureLow)    # print('最高温度:' + temperatureHigh+'℃')    # print('天气:' + weather)    today_weather = '南京今天的最低温度:' + low + ',最高温度:' + high + ',天气:' + weather + '。\n'    print('第二天的天气', today_weather)    return today_weatherdef get_low_high():    # 获取当天的天气的情况    # headers = get_header()    driver = webdriver.Chrome(executable_path=r'/Users/lvzeqin/Applications/chromedriver')    url = 'http://www.weather.com.cn/weather1d/101190101.shtml'    driver.get(url)    high_low = driver.find_element_by_xpath('//*[@id="w_weather"]/a[1]/em').text    high = high_low.split('/')[-1]    low = high_low.split('/')[0]    weather = driver.find_element_by_xpath('//*[@id="today"]/div[2]/ul/li[1]/p[1]').text    today_weather = '南京今天的最低温度:' + low + ',最高温度:' + high + ',天气:' + weather + '。\n'    print('当天的天气', today_weather)    driver.close()    return today_weatherif __name__ == '__main__':    # get_low_high()    get_weather()